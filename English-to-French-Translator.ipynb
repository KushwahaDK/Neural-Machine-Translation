{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the base Notebook for Neural Machine Translation (En-Fr translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:31:58.993693Z",
     "start_time": "2020-08-21T20:31:54.659472Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input, Embedding, LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:31:59.908256Z",
     "start_time": "2020-08-21T20:31:58.994609Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available GPUs : 1\n"
     ]
    }
   ],
   "source": [
    "#To check whether the Tensorflow is using or identifying the GPUs or not\",\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Number of available GPUs : {}\".format(len(physical_devices)))\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 1 : Data Fetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:31:59.918230Z",
     "start_time": "2020-08-21T20:31:59.912248Z"
    }
   },
   "outputs": [],
   "source": [
    "def fetch_data(data_path):\n",
    "    \"\"\" \n",
    "    This function will fetch the dataset with 'utf-8' encoding, \n",
    "    separate the source (en) and target (fr) language.\n",
    "    \n",
    "    input: path of the dataset txt file\n",
    "    output: list of all English text, list of corresponding French text\n",
    "    \"\"\"\n",
    "    with open(data_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.read().split('\\n')\n",
    "    en_text = []\n",
    "    fr_text = []\n",
    "    for line in lines:\n",
    "        en, fr, _ = line.split('\\t')\n",
    "        en_text.append(en)\n",
    "        fr_text.append(fr)\n",
    "        \n",
    "    return en_text, fr_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:32:00.106764Z",
     "start_time": "2020-08-21T20:31:59.919227Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_PATH = r'datasets/French-English/fra.txt'\n",
    "en_text, fr_text = fetch_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:32:00.116699Z",
     "start_time": "2020-08-21T20:32:00.107724Z"
    }
   },
   "outputs": [],
   "source": [
    "# fr_text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:32:00.132657Z",
     "start_time": "2020-08-21T20:32:00.117697Z"
    }
   },
   "outputs": [],
   "source": [
    "en_text = en_text[:50000]\n",
    "fr_text = fr_text[:50000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 2 : Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:32:00.139637Z",
     "start_time": "2020-08-21T20:32:00.135648Z"
    }
   },
   "outputs": [],
   "source": [
    "def text_clean(text):\n",
    "    \"\"\" \n",
    "    Function to clean the text before training.\n",
    "    input: text single line\n",
    "    output: cleaned text line\n",
    "    \"\"\"\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    # Replace the short words in there expanded forms\n",
    "    text = re.sub(\"i'm\", \"i am\", text)\n",
    "    text = re.sub(\"&\", \"and\", text)\n",
    "    \n",
    "    # remove all non essential charachters\n",
    "    text = re.sub(r\"[-{}\\\"#/@;:<>()+=|.?,%$!]\",\"\", text)\n",
    "    text = re.sub(r\"[0-9]\",\"\", text)\n",
    "    \n",
    "    # Remove outside spaces\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:32:00.498735Z",
     "start_time": "2020-08-21T20:32:00.141632Z"
    }
   },
   "outputs": [],
   "source": [
    "clean_en_text = [text_clean(text) for text in en_text]\n",
    "clean_fr_text = [text_clean(text) for text in fr_text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Data Formating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:32:00.503706Z",
     "start_time": "2020-08-21T20:32:00.499709Z"
    }
   },
   "outputs": [],
   "source": [
    "# Adding tokens to identify the start and end of TARGET language\n",
    "tokens = ['<SOS>', '<PAD>', '<EOS>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:32:00.533618Z",
     "start_time": "2020-08-21T20:32:00.505693Z"
    }
   },
   "outputs": [],
   "source": [
    "en_vocab = sorted(set((' '.join(clean_en_text)).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:32:00.538606Z",
     "start_time": "2020-08-21T20:32:00.534616Z"
    }
   },
   "outputs": [],
   "source": [
    "en_vocab.extend(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:32:00.575507Z",
     "start_time": "2020-08-21T20:32:00.539602Z"
    }
   },
   "outputs": [],
   "source": [
    "fr_vocab = sorted(set((' '.join(clean_fr_text)).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:32:00.580493Z",
     "start_time": "2020-08-21T20:32:00.576504Z"
    }
   },
   "outputs": [],
   "source": [
    "fr_vocab.extend(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:32:00.595453Z",
     "start_time": "2020-08-21T20:32:00.581491Z"
    }
   },
   "outputs": [],
   "source": [
    "en_word_idx = dict([(word, i) for i, word in enumerate(en_vocab)])\n",
    "en_idx_word = dict([(i, word) for i, word in enumerate(en_vocab)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:32:00.607427Z",
     "start_time": "2020-08-21T20:32:00.596451Z"
    }
   },
   "outputs": [],
   "source": [
    "fr_word_idx = dict([(word, i) for i, word in enumerate(fr_vocab)])\n",
    "fr_idx_word = dict([(i, word) for i, word in enumerate(fr_vocab)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:32:00.627368Z",
     "start_time": "2020-08-21T20:32:00.608418Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenise_fr_text = []\n",
    "for line in clean_fr_text:\n",
    "    tokenise_fr_text.append(tokens[0] + \" \" + line + \" \" + tokens[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:32:00.631357Z",
     "start_time": "2020-08-21T20:32:00.628365Z"
    }
   },
   "outputs": [],
   "source": [
    "complete_fr_text = tokenise_fr_text\n",
    "complete_en_text = clean_en_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:32:00.652349Z",
     "start_time": "2020-08-21T20:32:00.632355Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_en_seq_length = max([len(text.split()) for text in complete_en_text])\n",
    "max_en_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:32:00.678258Z",
     "start_time": "2020-08-21T20:32:00.653300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_fr_seq_length = max([len(text.split()) for text in complete_fr_text])\n",
    "max_fr_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:32:00.684236Z",
     "start_time": "2020-08-21T20:32:00.679230Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go', 'hi', 'hi', 'run', 'run']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_en_text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:32:00.689202Z",
     "start_time": "2020-08-21T20:32:00.685213Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<SOS> va <EOS>',\n",
       " '<SOS> salut <EOS>',\n",
       " '<SOS> salut <EOS>',\n",
       " '<SOS> cours <EOS>',\n",
       " '<SOS> courez <EOS>']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_fr_text[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding data with indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:32:00.858843Z",
     "start_time": "2020-08-21T20:32:00.692194Z"
    }
   },
   "outputs": [],
   "source": [
    "enc_en_text = [[en_word_idx[word] for word in line.split()] for line in complete_en_text]\n",
    "enc_fr_text = [[fr_word_idx[word] for word in line.split()] for line in complete_fr_text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Padding of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:32:01.130357Z",
     "start_time": "2020-08-21T20:32:00.859787Z"
    }
   },
   "outputs": [],
   "source": [
    "pad_en_text = pad_sequences(sequences=enc_en_text, maxlen=max_en_seq_length, padding='post', truncating='post', value=en_word_idx['<PAD>'])\n",
    "pad_fr_text = pad_sequences(sequences=enc_fr_text, maxlen=max_fr_seq_length, padding='post', truncating='post', value=fr_word_idx['<PAD>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:32:01.139257Z",
     "start_time": "2020-08-21T20:32:01.132275Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2242, 5980, 5980, ..., 5980, 5980, 5980],\n",
       "       [2495, 5980, 5980, ..., 5980, 5980, 5980],\n",
       "       [2495, 5980, 5980, ..., 5980, 5980, 5980],\n",
       "       ...,\n",
       "       [3195, 2617, 2429, ..., 5980, 5980, 5980],\n",
       "       [3195, 2617, 2759, ..., 5980, 5980, 5980],\n",
       "       [3195, 2617, 3083, ..., 3232, 5980, 5980]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_en_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:32:01.145273Z",
     "start_time": "2020-08-21T20:32:01.140255Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_en_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:32:01.151251Z",
     "start_time": "2020-08-21T20:32:01.147235Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12549, 11811, 12551, ..., 12550, 12550, 12550],\n",
       "       [12549, 10301, 12551, ..., 12550, 12550, 12550],\n",
       "       [12549, 10301, 12551, ..., 12550, 12550, 12550],\n",
       "       ...,\n",
       "       [12549,  9031,  3045, ..., 12550, 12550, 12550],\n",
       "       [12549,  9031,  6953, ..., 12550, 12550, 12550],\n",
       "       [12549,  9031,  5705, ..., 12550, 12550, 12550]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_fr_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:32:01.157208Z",
     "start_time": "2020-08-21T20:32:01.152222Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 16)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_fr_text.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Data preperation for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:44:15.002503Z",
     "start_time": "2020-08-21T20:44:14.990536Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(pad_en_text, pad_fr_text, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:44:15.571150Z",
     "start_time": "2020-08-21T20:44:15.566134Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45000, 8), (5000, 8))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:44:15.765644Z",
     "start_time": "2020-08-21T20:44:15.760657Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def data_batch_generator(X,y):\n",
    "max_en_seq_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:44:16.160587Z",
     "start_time": "2020-08-21T20:44:16.156598Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding_dim = 50\n",
    "en_vocab_len = len(en_vocab)\n",
    "fr_vocab_len = len(fr_vocab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:44:16.559599Z",
     "start_time": "2020-08-21T20:44:16.546634Z"
    }
   },
   "outputs": [],
   "source": [
    "# LAYERS\n",
    "encoder_input = Input(shape =(X_train.shape[1]))\n",
    "encoder_embedding_layer = Embedding(en_vocab_len , embedding_dim,input_length= max_en_seq_length)\n",
    "encoder_lstm_layer = LSTM(50, return_state = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:44:16.751122Z",
     "start_time": "2020-08-21T20:44:16.742111Z"
    }
   },
   "outputs": [],
   "source": [
    "# OUTPUTS\n",
    "encoder_embedding_output = encoder_embedding_layer(encoder_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:44:17.072232Z",
     "start_time": "2020-08-21T20:44:16.916644Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder_seq_output, encoder_memory_state, encoder_carry_state = encoder_lstm_layer(encoder_embedding_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:44:17.326173Z",
     "start_time": "2020-08-21T20:44:17.313207Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Model(encoder_input, encoder_seq_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:44:17.496045Z",
     "start_time": "2020-08-21T20:44:17.490056Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 8)]               0         \n",
      "_________________________________________________________________\n",
      "embedding_4 (Embedding)      (None, 8, 50)             299100    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                [(None, 50), (None, 50),  20200     \n",
      "=================================================================\n",
      "Total params: 319,300\n",
      "Trainable params: 319,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Decoder States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:44:18.057682Z",
     "start_time": "2020-08-21T20:44:18.052693Z"
    }
   },
   "outputs": [],
   "source": [
    "decoder_input = Input(shape=(y_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:44:18.321792Z",
     "start_time": "2020-08-21T20:44:18.318569Z"
    }
   },
   "outputs": [],
   "source": [
    "decoder_embedding_layer = Embedding(fr_vocab_len , embedding_dim,input_length= max_fr_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:44:18.540953Z",
     "start_time": "2020-08-21T20:44:18.533992Z"
    }
   },
   "outputs": [],
   "source": [
    "decoder_lstm_layer = LSTM(50, return_sequences=True, return_state=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:44:18.740448Z",
     "start_time": "2020-08-21T20:44:18.729468Z"
    }
   },
   "outputs": [],
   "source": [
    "decoder_embedding_output = decoder_embedding_layer(decoder_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:44:19.075521Z",
     "start_time": "2020-08-21T20:44:18.927946Z"
    }
   },
   "outputs": [],
   "source": [
    "decoder_seq_output, _, _ = decoder_lstm_layer(decoder_embedding_output, initial_state=[encoder_memory_state, encoder_carry_state])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:44:19.127383Z",
     "start_time": "2020-08-21T20:44:19.124418Z"
    }
   },
   "outputs": [],
   "source": [
    "decoder_dense = Dense(fr_vocab_len, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:44:19.500508Z",
     "start_time": "2020-08-21T20:44:19.482464Z"
    }
   },
   "outputs": [],
   "source": [
    "decoder_output = decoder_dense(decoder_seq_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:44:19.934252Z",
     "start_time": "2020-08-21T20:44:19.921290Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Model([encoder_input, decoder_input], decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:44:20.127739Z",
     "start_time": "2020-08-21T20:44:20.121744Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 8, 50)        299100      input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 16, 50)       627600      input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, 50), (None,  20200       embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   [(None, 16, 50), (No 20200       embedding_5[0][0]                \n",
      "                                                                 lstm_4[0][1]                     \n",
      "                                                                 lstm_4[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 16, 12552)    640152      lstm_5[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,607,252\n",
      "Trainable params: 1,607,252\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:44:20.496751Z",
     "start_time": "2020-08-21T20:44:20.485792Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:44:20.792955Z",
     "start_time": "2020-08-21T20:44:20.789970Z"
    }
   },
   "outputs": [],
   "source": [
    "# prepare decoder input and target data format using a generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:44:21.019974Z",
     "start_time": "2020-08-21T20:44:21.012993Z"
    }
   },
   "outputs": [],
   "source": [
    "# prepare decoder input and target data format using a generator\n",
    "def batch_data_generator(X, y, batch_size=64):\n",
    "    while True:\n",
    "        for batch in range (0, X_train.shape[0], batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, X_train.shape[1]), dtype = 'int32')\n",
    "            decoder_input_data = np.zeros((batch_size, y_train.shape[1]), dtype = 'int32')\n",
    "            decoder_target_data = np.zeros((batch_size, y_train.shape[1] ,fr_vocab_len) ,dtype = 'int32')\n",
    "\n",
    "            for seq_index, (input_seq, target_seq) in enumerate(zip(X[batch:batch+batch_size], y[batch:batch+batch_size])):\n",
    "                    \n",
    "                    for word_index, word in enumerate(input_seq):\n",
    "                        encoder_input_data[seq_index, word_index] = word \n",
    "                    for word_index, word in enumerate(target_seq):\n",
    "                        if word_index<len(target_seq)-1: \n",
    "                            decoder_input_data[seq_index, word_index] = word # decoder input seq\n",
    "                        if word_index>0: \n",
    "                            decoder_target_data[seq_index, word_index - 1, word] = 1.\n",
    "\n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:44:21.191517Z",
     "start_time": "2020-08-21T20:44:21.188523Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 10\n",
    "steps_per_epoch = (X_train.shape[0]/batch_size)\n",
    "val_steps = (X_test.shape[0]/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:57:48.810094Z",
     "start_time": "2020-08-21T20:44:21.515658Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "704/703 [==============================] - 80s 113ms/step - loss: 2.4956 - accuracy: 0.6405\n",
      "Epoch 2/10\n",
      "704/703 [==============================] - 80s 114ms/step - loss: 1.6387 - accuracy: 0.6964\n",
      "Epoch 3/10\n",
      "704/703 [==============================] - 81s 115ms/step - loss: 1.4424 - accuracy: 0.7158\n",
      "Epoch 4/10\n",
      "704/703 [==============================] - 80s 113ms/step - loss: 1.3161 - accuracy: 0.7294\n",
      "Epoch 5/10\n",
      "704/703 [==============================] - 80s 113ms/step - loss: 1.2196 - accuracy: 0.7419\n",
      "Epoch 6/10\n",
      "704/703 [==============================] - 80s 114ms/step - loss: 1.1387 - accuracy: 0.7506\n",
      "Epoch 7/10\n",
      "704/703 [==============================] - 80s 114ms/step - loss: 1.0727 - accuracy: 0.7574\n",
      "Epoch 8/10\n",
      "704/703 [==============================] - 82s 116ms/step - loss: 1.0146 - accuracy: 0.7635\n",
      "Epoch 9/10\n",
      "704/703 [==============================] - 81s 114ms/step - loss: 0.9632 - accuracy: 0.7684\n",
      "Epoch 10/10\n",
      "704/703 [==============================] - 81s 115ms/step - loss: 0.9167 - accuracy: 0.7729\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(batch_data_generator(X_train, y_train,batch_size), steps_per_epoch = steps_per_epoch, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T20:58:19.940597Z",
     "start_time": "2020-08-21T20:58:19.848776Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save('models/en_fr_vanialla_LSTM_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T21:11:17.966155Z",
     "start_time": "2020-08-21T21:11:17.964151Z"
    }
   },
   "outputs": [],
   "source": [
    "# encoder_model = Model(encoder_input, [encoder_memory_state, encoder_carry_state])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T21:13:59.129414Z",
     "start_time": "2020-08-21T21:13:58.936852Z"
    }
   },
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the \"Context vectors\"\n",
    "encoder_model = Model(encoder_input , [encoder_memory_state, encoder_carry_state])\n",
    "\n",
    "# Decoder setup\n",
    "\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(50,))\n",
    "decoder_state_input_c = Input(shape=(50,))\n",
    "decoder_state_input = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# Get the embeddings of the decoder sequence\n",
    "dec_emb2 = decoder_embedding_layer(decoder_input)\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm_layer(dec_emb2, initial_state=decoder_state_input)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "\n",
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_input] + decoder_state_input,\n",
    "    [decoder_outputs2] + decoder_states2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T21:16:57.399606Z",
     "start_time": "2020-08-21T21:16:57.392624Z"
    }
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "        # Encode the input as state vectors.\n",
    "        states_value = encoder_model.predict(input_seq)\n",
    "        \n",
    "        # Generate empty target sequence of length 1.\n",
    "        target_seq = np.zeros((1,1))\n",
    "        \n",
    "        # Populate the first character of \n",
    "        #target sequence with the start character.\n",
    "        target_seq[0, 0] = fr_word_idx['<SOS>']\n",
    "        \n",
    "        # Sampling loop for a batch of sequences\n",
    "        # (to simplify, here we assume a batch of size 1).\n",
    "        stop_condition = False\n",
    "        decoded_sentence = ''\n",
    "        \n",
    "        while not stop_condition:\n",
    "            output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "            \n",
    "            # Sample a token\n",
    "            sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "            sampled_word =fr_idx_word[sampled_token_index]\n",
    "            decoded_sentence += ' '+ sampled_word\n",
    "            \n",
    "            # Exit condition: either hit max length\n",
    "            # or find stop character.\n",
    "            if (sampled_word == '<EOS>' or len(decoded_sentence.split()) > 25):\n",
    "                stop_condition = True\n",
    "        \n",
    "            # Update the target sequence (of length 1).\n",
    "            target_seq = np.zeros((1,1))\n",
    "            target_seq[0, 0] = sampled_token_index\n",
    "            \n",
    "            # Update states\n",
    "            states_value = [h, c]\n",
    "        return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T21:32:33.082038Z",
     "start_time": "2020-08-21T21:32:33.078049Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a batch generator for batch size 1\n",
    "train_gen = batch_data_generator(X_test, y_test, batch_size = 1)\n",
    "k=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T21:33:22.003072Z",
     "start_time": "2020-08-21T21:33:21.735775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5960 1545 2429 5364 2242 5980 5980 5980]]\n",
      "you don't have to go\n",
      "Input Source sentence: do it at once\n",
      "Actual Target Sentence: faitesle immédiatement\n",
      "Predicted Target Sentence: vous ne vous n'êtes pas\n"
     ]
    }
   ],
   "source": [
    "# Predict the target sentence and compare with the actual target sentence given a source sentence\n",
    "k+=1000\n",
    "(input_seq, actual_output), target_output = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "# print(input_seq)\n",
    "print(en_idx_word[input_seq[0][0]],en_idx_word[input_seq[0][1]], en_idx_word[input_seq[0][2]], en_idx_word[input_seq[0][3]], en_idx_word[input_seq[0][4]])\n",
    "print('Input Source sentence:', clean_en_text[k:k+1][0])\n",
    "print('Actual Target Sentence:', clean_fr_text[k:k+1][0])\n",
    "print('Predicted Target Sentence:', decoded_sentence[:-5].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
