{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the base Notebook for Neural Machine Translation (En-Fr translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T20:31:28.637127Z",
     "start_time": "2020-08-20T20:31:19.214892Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input, Embedding, LSTM\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 1 : Data Fetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T20:31:28.649932Z",
     "start_time": "2020-08-20T20:31:28.643948Z"
    }
   },
   "outputs": [],
   "source": [
    "def fetch_data(data_path):\n",
    "    \"\"\" \n",
    "    This function will fetch the dataset with 'utf-8' encoding, \n",
    "    separate the source (en) and target (fr) language.\n",
    "    \n",
    "    input: path of the dataset txt file\n",
    "    output: list of all English text, list of corresponding French text\n",
    "    \"\"\"\n",
    "    with open(data_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.read().split('\\n')\n",
    "    en_text = []\n",
    "    fr_text = []\n",
    "    for line in lines:\n",
    "        en, fr, _ = line.split('\\t')\n",
    "        en_text.append(en)\n",
    "        fr_text.append(fr)\n",
    "        \n",
    "    return en_text, fr_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T20:31:29.131096Z",
     "start_time": "2020-08-20T20:31:28.652078Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_PATH = r'datasets/French-English/fra.txt'\n",
    "en_text, fr_text = fetch_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T20:31:29.137034Z",
     "start_time": "2020-08-20T20:31:29.134081Z"
    }
   },
   "outputs": [],
   "source": [
    "# fr_text[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 2 : Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T20:31:29.146040Z",
     "start_time": "2020-08-20T20:31:29.139568Z"
    }
   },
   "outputs": [],
   "source": [
    "def text_clean(text):\n",
    "    \"\"\" \n",
    "    Function to clean the text before training.\n",
    "    input: text single line\n",
    "    output: cleaned text line\n",
    "    \"\"\"\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    # Replace the short words in there expanded forms\n",
    "    text = re.sub(\"i'm\", \"i am\", text)\n",
    "    text = re.sub(\"&\", \"and\", text)\n",
    "    \n",
    "    # remove all non essential charachters\n",
    "    text = re.sub(r\"[-{}\\\"#/@;:<>()+=|.?,%$!]\",\"\", text)\n",
    "    text = re.sub(r\"[0-9]\",\"\", text)\n",
    "    \n",
    "    # Remove outside spaces\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T20:31:32.437219Z",
     "start_time": "2020-08-20T20:31:29.149034Z"
    }
   },
   "outputs": [],
   "source": [
    "clean_en_text = [text_clean(text) for text in en_text]\n",
    "clean_fr_text = [text_clean(text) for text in fr_text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Data Formating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T20:31:32.442205Z",
     "start_time": "2020-08-20T20:31:32.439210Z"
    }
   },
   "outputs": [],
   "source": [
    "# Adding tokens to identify the start and end of TARGET language\n",
    "tokens = ['<SOS>', '<PAD>', '<EOS>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T20:31:32.807328Z",
     "start_time": "2020-08-20T20:31:32.447223Z"
    }
   },
   "outputs": [],
   "source": [
    "en_vocab = sorted(set((' '.join(clean_en_text)).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T20:31:32.817159Z",
     "start_time": "2020-08-20T20:31:32.811189Z"
    }
   },
   "outputs": [],
   "source": [
    "en_vocab.extend(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T20:31:33.356011Z",
     "start_time": "2020-08-20T20:31:32.820662Z"
    }
   },
   "outputs": [],
   "source": [
    "fr_vocab = sorted(set((' '.join(clean_fr_text)).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T20:31:33.363022Z",
     "start_time": "2020-08-20T20:31:33.359034Z"
    }
   },
   "outputs": [],
   "source": [
    "fr_vocab.extend(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T20:31:33.415974Z",
     "start_time": "2020-08-20T20:31:33.364989Z"
    }
   },
   "outputs": [],
   "source": [
    "en_word_idx = dict([(word, i) for i, word in enumerate(en_vocab)])\n",
    "en_idx_word = dict([(i, word) for i, word in enumerate(en_vocab)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T20:31:33.485276Z",
     "start_time": "2020-08-20T20:31:33.417921Z"
    }
   },
   "outputs": [],
   "source": [
    "fr_word_idx = dict([(word, i) for i, word in enumerate(fr_vocab)])\n",
    "fr_idx_word = dict([(i, word) for i, word in enumerate(fr_vocab)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T20:31:33.747088Z",
     "start_time": "2020-08-20T20:31:33.492263Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenise_fr_text = []\n",
    "for line in clean_fr_text:\n",
    "    tokenise_fr_text.append(tokens[0] + \" \" + line + \" \" + tokens[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T20:31:33.761183Z",
     "start_time": "2020-08-20T20:31:33.752658Z"
    }
   },
   "outputs": [],
   "source": [
    "complete_fr_text = tokenise_fr_text\n",
    "complete_en_text = clean_en_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T20:31:33.932169Z",
     "start_time": "2020-08-20T20:31:33.768537Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_en_seq_length = max([len(text.split()) for text in complete_en_text])\n",
    "max_en_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T20:31:34.199027Z",
     "start_time": "2020-08-20T20:31:33.938440Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_fr_seq_length = max([len(text.split()) for text in complete_fr_text])\n",
    "max_fr_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T20:31:34.205822Z",
     "start_time": "2020-08-20T20:31:34.201065Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go', 'hi', 'hi', 'run', 'run']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_en_text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T20:31:34.214844Z",
     "start_time": "2020-08-20T20:31:34.207820Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<SOS> va <EOS>',\n",
       " '<SOS> salut <EOS>',\n",
       " '<SOS> salut <EOS>',\n",
       " '<SOS> cours <EOS>',\n",
       " '<SOS> courez <EOS>']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_fr_text[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding data with indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T20:31:36.131374Z",
     "start_time": "2020-08-20T20:31:34.221952Z"
    }
   },
   "outputs": [],
   "source": [
    "enc_en_text = [[en_word_idx[word] for word in line.split()] for line in complete_en_text]\n",
    "enc_fr_text = [[fr_word_idx[word] for word in line.split()] for line in complete_fr_text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Padding of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T20:31:38.723641Z",
     "start_time": "2020-08-20T20:31:36.133304Z"
    }
   },
   "outputs": [],
   "source": [
    "pad_en_text = pad_sequences(sequences=enc_en_text, maxlen=max_en_seq_length, padding='post', truncating='post', value=en_word_idx['<PAD>'])\n",
    "pad_fr_text = pad_sequences(sequences=enc_fr_text, maxlen=max_fr_seq_length, padding='post', truncating='post', value=fr_word_idx['<PAD>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T20:31:38.730711Z",
     "start_time": "2020-08-20T20:31:38.725574Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5603, 14726, 14726, ..., 14726, 14726, 14726],\n",
       "       [ 6157, 14726, 14726, ..., 14726, 14726, 14726],\n",
       "       [ 6157, 14726, 14726, ..., 14726, 14726, 14726],\n",
       "       ...,\n",
       "       [ 3336,  6975, 12015, ..., 14726, 14726, 14726],\n",
       "       [11699, 13072,   663, ...,  7443,  6973, 14726],\n",
       "       [ 6496, 12010, 14395, ...,     5,  8471, 12093]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_en_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T20:31:38.738689Z",
     "start_time": "2020-08-20T20:31:38.733702Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(177210, 44)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_en_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T20:31:38.743974Z",
     "start_time": "2020-08-20T20:31:38.739719Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[29594, 27919, 29596, ..., 29595, 29595, 29595],\n",
       "       [29594, 24489, 29596, ..., 29595, 29595, 29595],\n",
       "       [29594, 24489, 29596, ..., 29595, 29595, 29595],\n",
       "       ...,\n",
       "       [29594, 14864, 17084, ..., 29595, 29595, 29595],\n",
       "       [29594, 21192, 28742, ..., 29595, 29595, 29595],\n",
       "       [29594, 24969, 21542, ..., 15256, 17950, 29596]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_fr_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T20:31:38.749945Z",
     "start_time": "2020-08-20T20:31:38.744931Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(177210, 57)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_fr_text.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Data preperation for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T20:31:38.875838Z",
     "start_time": "2020-08-20T20:31:38.752633Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(pad_en_text, pad_fr_text, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T20:31:38.884556Z",
     "start_time": "2020-08-20T20:31:38.878758Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((141768, 44), (141768, 57))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T20:31:38.891548Z",
     "start_time": "2020-08-20T20:31:38.886572Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def data_batch_generator(X,y):\n",
    "max_en_seq_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T20:31:38.897521Z",
     "start_time": "2020-08-20T20:31:38.893534Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding_dim = 50\n",
    "en_vocab_len = len(en_vocab)\n",
    "fr_vocab_len = len(fr_vocab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T20:31:43.916168Z",
     "start_time": "2020-08-20T20:31:38.899649Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# LAYERS\n",
    "encoder_input = Input(shape =(X_train.shape[1]))\n",
    "encoder_embedding_layer = Embedding(en_vocab_len , embedding_dim,input_length= max_en_seq_length)\n",
    "encoder_lstm_layer = LSTM(50, return_state = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T20:31:43.988083Z",
     "start_time": "2020-08-20T20:31:43.919112Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "# OUTPUTS\n",
    "encoder_embedding_output = encoder_embedding_layer(encoder_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T20:31:45.060030Z",
     "start_time": "2020-08-20T20:31:43.991108Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder_seq_output, encoder_memory_state, encoder_carry_state = encoder_lstm_layer(encoder_embedding_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T20:32:00.680026Z",
     "start_time": "2020-08-20T20:32:00.661476Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_input, encoder_seq_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T20:33:28.562993Z",
     "start_time": "2020-08-20T20:33:28.553018Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 44)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 44, 50)            736400    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  [(None, 50), (None, 50),  20200     \n",
      "=================================================================\n",
      "Total params: 756,600\n",
      "Trainable params: 756,600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Decoder States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T21:05:58.575302Z",
     "start_time": "2020-08-20T21:05:58.567658Z"
    }
   },
   "outputs": [],
   "source": [
    "decoder_input = Input(shape=(y_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T21:05:58.806835Z",
     "start_time": "2020-08-20T21:05:58.798339Z"
    }
   },
   "outputs": [],
   "source": [
    "decoder_embedding_layer = Embedding(fr_vocab_len , embedding_dim,input_length= max_fr_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T21:08:31.290427Z",
     "start_time": "2020-08-20T21:08:31.282657Z"
    }
   },
   "outputs": [],
   "source": [
    "decoder_lstm_layer = LSTM(50, return_sequences=True, return_state=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T21:08:31.780891Z",
     "start_time": "2020-08-20T21:08:31.772557Z"
    }
   },
   "outputs": [],
   "source": [
    "decoder_embedding_output = decoder_embedding_layer(decoder_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T21:08:32.973888Z",
     "start_time": "2020-08-20T21:08:32.345133Z"
    }
   },
   "outputs": [],
   "source": [
    "decoder_seq_output, _, _ = decoder_lstm_layer(decoder_embedding_output, initial_state=[encoder_memory_state, encoder_carry_state])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T21:08:35.243924Z",
     "start_time": "2020-08-20T21:08:35.240202Z"
    }
   },
   "outputs": [],
   "source": [
    "decoder_dense = Dense(fr_vocab_len, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T21:08:35.800085Z",
     "start_time": "2020-08-20T21:08:35.774659Z"
    }
   },
   "outputs": [],
   "source": [
    "decoder_output = decoder_dense(decoder_seq_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T21:08:37.507218Z",
     "start_time": "2020-08-20T21:08:37.490420Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Model([encoder_input, decoder_input], decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T21:08:39.040411Z",
     "start_time": "2020-08-20T21:08:39.026343Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 44)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 57)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 44, 50)       736400      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 57, 50)       1479850     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 50), (None,  20200       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 57, 50), (No 20200       embedding_1[0][0]                \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 57, 29597)    1509447     lstm_1[1][0]                     \n",
      "==================================================================================================\n",
      "Total params: 3,766,097\n",
      "Trainable params: 3,766,097\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T21:13:47.067848Z",
     "start_time": "2020-08-20T21:13:46.748886Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T21:15:49.766481Z",
     "start_time": "2020-08-20T21:15:49.760203Z"
    }
   },
   "outputs": [],
   "source": [
    "# prepare decoder input and target data format using a generator\n",
    "def batch_data_generator(X, y, batch_size=64):\n",
    "    while True:\n",
    "        for batch in range (0, X_train.shape[0], batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, X_train.shape[1]), dtype = 'int32')\n",
    "            decoder_input_data = np.zeros((batch_size, y_train.shape[1]), dtype = 'int32')\n",
    "            decoder_target_data = np.zeros((batch_size, y_train.shape[1] ,fr_vocab_len) ,dtype = 'int32')\n",
    "\n",
    "            for seq_index, (input_seq, target_seq) in enumerate(zip(X[batch:batch+batch_size], y[batch:batch+batch_size])):\n",
    "                    \n",
    "                    for word_index, word in enumerate(input_seq):\n",
    "                        encoder_input_data[seq_index, word_index] = word\n",
    "                    \n",
    "                    for word_index, word in enumerate(target_seq):\n",
    "                        if word_index<len(target_seq)-1: \n",
    "                            decoder_input_data[seq_index, word_index] = word # decoder input seq\n",
    "                        if word_index>0: \n",
    "                            decoder_target_data[seq_index, word_index - 1, word] = 1.\n",
    "\n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data) \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 2\n",
    "steps_per_epoch = (X_train.shape[0]/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "   1/2215 [..............................] - ETA: 31:51:48 - loss: 10.1137 - acc: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "history = model.fit(batch_data_generator(X_train, y_train,batch_size), \n",
    "                    steps_per_epoch = steps_per_epoch,\n",
    "                    epochs=epochs,\n",
    "                    verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
